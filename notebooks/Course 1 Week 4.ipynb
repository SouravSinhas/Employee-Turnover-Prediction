{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse01-0.png', 'horse01-1.png', 'horse01-2.png', 'horse01-3.png', 'horse01-4.png', 'horse01-5.png', 'horse01-6.png', 'horse01-7.png', 'horse01-8.png', 'horse01-9.png']\n",
      "['human01-00.png', 'human01-01.png', 'human01-02.png', 'human01-03.png', 'human01-04.png', 'human01-05.png', 'human01-06.png', 'human01-07.png', 'human01-08.png', 'human01-09.png']\n",
      "\n",
      "Total number of horse images:  500\n",
      "\n",
      "Total number of human images:  527\n"
     ]
    }
   ],
   "source": [
    "# Unzipping file\n",
    "\n",
    "# Defining path to the zip file\n",
    "local_zip = \"D:/Work/Research/Dropbox/Machine Learning/Coursera/Tensorflow in Practice Specialization/Course 1 - Intro to Tensorflow/Assignments/Exercise/Training/horse-or-human.zip\"\n",
    "# Defining the reading function to zup file\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "# Extracting the zip file: Creates another folder called \"horse-or-human\" and two subfolders named \"horses\" and \"humans\"\n",
    "zip_ref.extractall('D:\\Work\\Research\\Dropbox\\Machine Learning\\Coursera\\Tensorflow in Practice Specialization\\Course 1 - Intro to Tensorflow\\Assignments\\Exercise\\Training\\horse-or-human')\n",
    "zip_ref.close()\n",
    "\n",
    "# Pointing to the main directory containing the two subfolders\n",
    "train_horse_dir = os.path.join(\"D:\\Work\\Research\\Dropbox\\Machine Learning\\Coursera\\Tensorflow in Practice Specialization\\Course 1 - Intro to Tensorflow\\Assignments\\Exercise\\Training\\horse-or-human\\horses\")\n",
    "train_human_dir = os.path.join(\"D:\\Work\\Research\\Dropbox\\Machine Learning\\Coursera\\Tensorflow in Practice Specialization\\Course 1 - Intro to Tensorflow\\Assignments\\Exercise\\Training\\horse-or-human\\humans\")\n",
    "\n",
    "# Listing the items in each folder\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_horse_names[:10])\n",
    "print(train_human_names[:10])\n",
    "print('\\nTotal number of horse images: ', len(train_horse_names))\n",
    "print(\"\\nTotal number of human images: \", len(train_human_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing loaded information for the training set\n",
    "\n",
    "# Defining the image data generator function which rescales each image pixel \n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "# Then defining the generator function\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    # Specify directory name : NOTE - main directory name, and not subdirectory name\n",
    "                    \"D:\\Work\\Research\\Dropbox\\Machine Learning\\Coursera\\Tensorflow in Practice Specialization\\Course 1 - Intro to Tensorflow\\Assignments\\Exercise\\Training\\horse-or-human\",\n",
    "                    # Target size to which the image should be resized to before being trained on\n",
    "                    target_size = (300,300),\n",
    "                    # Batch size to be processed in one go\n",
    "                    batch_size = 128,\n",
    "                    # Binary labels to be applied to images, since we are using a binary classifier\n",
    "                    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 355216)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               181871104 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 181,872,065\n",
      "Trainable params: 181,872,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (300,300,3)), #The (300,300,3) is for a colored image with 3 channels\n",
    "        tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "        #tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "        #tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "        #tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "        #tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "        #tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "        #tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "        #tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "        #tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer = RMSprop(lr = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/8 [==>...........................] - ETA: 30:07 - loss: 0.6864 - acc: 0.6667"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch = 8, # Comes from the fact that there are about 1027 images and 128 images in each batch\n",
    "                   epochs = 15,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-668606cd4276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Actually loading images and then checking what the predictions are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Actually loading images and then checking what the predictions are \n",
    "\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-1479db6fe56a>\", line 2, in <module>\n",
      "    uploaded = files.upload()\n",
      "NameError: name 'files' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 173, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Public\\anaconda3\\lib\\inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Uploading files instruction and then prediction label\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    \n",
    "    path = \"/content/\" + fn\n",
    "    img = image.load_img(path, target_size = (300,300))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size = 10)\n",
    "    print(classes[0])\n",
    "    if(classes[0]>0.5):\n",
    "        print(fn + 'is a human.')\n",
    "    else:\n",
    "        print(fn + 'is a horse.')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding automatic Validation to the code\n",
    "\n",
    "# Loading the validation data and extracting the zip file\n",
    "local_zip = 'D:\\Work\\Research\\Dropbox\\Machine Learning\\Coursera\\Tensorflow in Practice Specialization\\Course 1 - Intro to Tensorflow\\Assignments\\Exercise\\Validation\\validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('D:\\Work\\Research\\Dropbox\\Machine Learning\\Coursera\\Tensorflow in Practice Specialization\\Course 1 - Intro to Tensorflow\\Assignments\\Exercise\\Validation\\validation-horse-or-human')\n",
    "zip_ref.close()\n",
    "\n",
    "# Defining validation directories\n",
    "validation_horse_names = os.listdir(validation_horse_dir)\n",
    "validation_human_names = os.listdir(validation_human_dir)\n",
    "print(validation_horse_names[:10])\n",
    "print(validation_human_names[:10])\n",
    "print('\\nTotal number of horse images: ', len(validation_horse_names))\n",
    "print(\"\\nTotal number of human images: \", len(validation_human_names))\n",
    "\n",
    "\n",
    "validation_horse_hames = os.listdir(validation_horse_dir)\n",
    "print(validation_horse_hames[:10])\n",
    "validation_human_names = os.listdir(validation_human_dir)\n",
    "print(validation_human_names[:10])\n",
    "\n",
    "# Defining data generator for validation images\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'D:\\Work\\Research\\Dropbox\\Machine Learning\\Coursera\\Tensorflow in Practice Specialization\\Course 1 - Intro to Tensorflow\\Assignments\\Exercise\\Validation\\validation-horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Fitting the model\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch = 8,\n",
    "            epochs = 15,\n",
    "            verbose = 1,\n",
    "            validation_data = validation_generator,\n",
    "            validation_steps = 8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGTERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
